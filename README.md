Boyer–Moore Majority Vote Algorithm: Theoretical and Empirical Study

Algorithm Overview

The Boyer–Moore Majority Vote algorithm addresses the problem of identifying the majority element in a sequence — that is, an element that appears more than ⌊n / 2⌋ times in an array of size n. The algorithm relies on a simple yet elegant voting principle: if we pair distinct elements and discard them, the majority element (if one exists) will remain unpaired at the end. The implementation in this project follows the canonical two-phase approach. In the first phase, the algorithm scans the array once while maintaining a candidate element and a counter that represents the current "vote balance." Whenever the counter reaches zero, the current element becomes the new candidate, and the counter is reset. This ensures that all non-majority elements are effectively canceled out over time. In the second phase, the candidate is verified by counting its occurrences in a separate pass to confirm whether it indeed exceeds half of the total length.

The project integrates this core logic into an instrumented implementation that tracks primitive operations such as comparisons and array accesses through a dedicated PerformanceTracker utility. This allows quantitative study of the algorithm’s behavior under various input distributions and provides insight into constant-factor effects that are invisible in purely asymptotic analysis. The CLI benchmarking harness automates generation of arrays with different structural characteristics—random, sorted, reverse-sorted, nearly sorted, and adversarial (“worst-case”)—and collects timing and operation counts into CSV output for empirical comparison.

Complexity Analysis

The Boyer–Moore Majority Vote algorithm runs in linear time. In the first phase, a single pass through the array is performed, and for each of the n elements the algorithm executes a constant number of primitive operations: a comparison, a conditional update of the candidate, and a counter increment or decrement. The total cost therefore satisfies the recurrence T(n) = T(n−1) + Θ(1), which unrolls to T(n) = Θ(n). Because no nested loops or recursive calls are involved, the best, average, and worst-case running times coincide, each being linear in n. The only minor variation lies in the frequency of counter resets, which changes slightly with the data distribution but never affects the overall asymptotic classification.

The second verification phase also performs a linear scan to count occurrences of the candidate element, adding another Θ(n) term. Combining both passes yields T_total(n) = 2Θ(n), which simplifies to Θ(n). Hence, the algorithm’s runtime is tightly bounded by linear growth. In asymptotic notation, T(n) ∈ Θ(n), O(n), and Ω(n).

Space complexity is minimal: the algorithm maintains only two scalar variables in addition to the input array—a current candidate and a counter—resulting in constant auxiliary space S(n) = Θ(1). This in-place nature makes Boyer–Moore especially attractive for memory-constrained environments or embedded systems, since no auxiliary arrays, hash maps, or dynamic data structures are required. The verification phase reuses the same memory footprint, further confirming the algorithm’s constant-space property.

Empirical Results

Empirical validation was performed using the project’s benchmarking framework, which measures runtime in nanoseconds for multiple input sizes (100, 1 000, and 10 000) and distributions. Results are stored in data/boyer-benchmarks.csv and reveal near-linear scaling consistent with theoretical expectations. As input size increases by a factor of ten, average runtime rises by approximately 6–12×, which reflects the constant per-element processing cost of the algorithm. Variations among distributions primarily arise from low-level effects: nearly sorted arrays tend to execute faster due to fewer candidate changes and branch mispredictions, whereas random and worst-case arrays trigger more frequent resets of the candidate, slightly increasing total comparisons.

Despite these minor fluctuations, the empirical data confirm that both the best and worst scenarios remain tightly bound to linear behavior. For instance, reverse-sorted arrays exhibit comparable timing to random distributions, demonstrating that Boyer–Moore’s logic does not depend on input ordering. The observed nanosecond-level timings scale predictably with n, and the constant-space characteristic ensures stable memory usage across all runs. These results collectively validate the theoretical analysis: the Boyer–Moore Majority Vote algorithm achieves Θ(n) time and Θ(1) space complexity in practice, providing an optimal and elegant solution to the majority element problem.

The dataset can be regenerated by invoking the CLI (for example, mvn -q exec:java -Dexec.mainClass=cli.BenchmarkRunner), after which the resulting CSV will include the average, minimum, and maximum timings for each tested configuration. The close match between measured and theoretical behavior reinforces the conclusion that the Boyer–Moore Majority Vote algorithm is both asymptotically optimal and empirically efficient.
